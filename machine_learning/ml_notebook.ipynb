{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine learning notebook for FDD Project @ Vasakronan summer internship 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, d2_tweedie_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "directory = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create machine learning model for the generated energy/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_energy_day_models():\n",
    "        k = 0\n",
    "        files = Path(directory).glob('**/*.csv')\n",
    "        for filepath in files:\n",
    "                print(filepath)\n",
    "                if 'uppsala' not in str(filepath):\n",
    "                        data = pd.read_csv(filepath, skipinitialspace=True)\n",
    "                        building_id = data['buildingId'][0]\n",
    "                        # meter_id = data['metry_meter_id'][0]\n",
    "                        # print(\"doing id: \" + meter_id)\n",
    "                        data = data.dropna(how = 'any')\n",
    "                        data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "                        new_data = data.groupby(data.date_time.dt.date).agg({\"value\": \"sum\", \"energy\": \"sum\", \"outdoorTemperature\": \"sum\", \"humidity\": \"sum\", \"month\": \"mean\"})\n",
    "                        print(new_data)\n",
    "                        print(building_id)\n",
    "                        # data['month'] = pd.to_datetime(\n",
    "                        # data.round({'irradiance': 1, 'generated_energy': 1})\n",
    "\n",
    "                        x = new_data[[\"value\", \"month\", \"outdoorTemperature\", \"humidity\"]]\n",
    "                        y = np.asarray(new_data[[\"energy\"]])\n",
    "                        if len(y) == 0:\n",
    "                                continue\n",
    "                        \n",
    "                        x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                x, y, test_size=0.1, random_state=13)\n",
    "\n",
    "                        model = RandomForestRegressor(max_features=\"auto\", bootstrap=True,\n",
    "                        max_depth= 80,\n",
    "                        min_samples_leaf= 5,\n",
    "                        min_samples_split= 12,\n",
    "                        n_estimators= 100)\n",
    "                        model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "                        print(model.score(x_test, y_test))\n",
    "\n",
    "                        preds = model.predict(x_test)\n",
    "\n",
    "                        pickle.dump(model, open(f'./model_{building_id}_energy_per_day.pkl', 'wb'))\n",
    "                        k += 1\n",
    "\n",
    "create_energy_day_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_effect_hour_models():\n",
    "    data = pd.read_csv('./data_biomedit1.csv')\n",
    "    print(data)\n",
    "    data['value'] = data['value']*335\n",
    "    x = data[[\"value\", \"month\", 'humidity', 'outdoorTemperature']]\n",
    "    y = np.asarray(data[[\"energy\"]])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=0.20)\n",
    "            \n",
    "   # model = MLPRegressor(activation = 'tanh', alpha = 0.05, early_stopping = True, hidden_layer_sizes = (400, 1000, 1200), learning_rate = 'constant', max_iter = 10000, solver = 'adam', verbose=True)\n",
    "    model = RandomForestRegressor(max_features=\"auto\", bootstrap=True,\n",
    "       max_depth= 500,\n",
    "       min_samples_leaf= 5,\n",
    "       min_samples_split= 12,\n",
    "       n_estimators= 100)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    print(model.score(x_test, y_test))\n",
    "    pickle.dump(model, open(f'model_biomedi1v2_forest.pkl', 'wb'))\n",
    "    #pickle.dump(scalerx, open(f'scalerx_{meter_id}.pkl', 'wb'))\n",
    "    #pickle.dump(scalery, open(f'scalery_{meter_id}.pkl', 'wb'))\n",
    "    preds = model.predict(x_test)\n",
    "    \n",
    "\n",
    "    # print(model.score(x_test, y_test))\n",
    "    # pickle.dump(model, open(f'model_{meter_id}.pkl', 'wb'))\n",
    "    return model, preds, y_test\n",
    "\n",
    "model, preds, y_test = create_effect_hour_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (30, 10)\n",
    "plt.plot(model.loss_curve_)\n",
    "plt.title(\"Loss Curve\", fontsize=14)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_up = [i*1.10 for i in preds[:70].tolist()]\n",
    "preds_down = [i*0.90 for i in preds[:70].tolist()]\n",
    "x = np.linspace(0,69,70)\n",
    "plt.rcParams['figure.figsize'] = (30, 10)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_test[:70], label='Actual values')\n",
    "ax.plot(preds[:70], 'r', label='ML prediction')\n",
    "ax.fill_between(x, np.array(preds_up), np.array(preds_down), color=\"gray\", alpha=0.5, label='20% interval around ML preds')\n",
    "leg = ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d2_tweedie_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./sthlm_csv_test2.csv')\n",
    "data = data.dropna(how = 'any')\n",
    "\n",
    "def mlp_model(X, Y):\n",
    "\n",
    "    estimator=MLPRegressor()\n",
    "\n",
    "\n",
    "    param_grid = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,1)],\n",
    "            'activation': ['relu','tanh','logistic'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive'],\n",
    "            'solver': ['adam']}\n",
    "\n",
    "    gsc = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid,\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "    grid_result = gsc.fit(X, Y)\n",
    "\n",
    "\n",
    "    best_params = grid_result.best_params_\n",
    "    print(best_params)\n",
    "\n",
    "    best_mlp = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], \n",
    "                            activation =best_params[\"activation\"],\n",
    "                            solver=best_params[\"solver\"],\n",
    "                            max_iter= 5000, n_iter_no_change = 200\n",
    "                )\n",
    "\n",
    "    scoring = {\n",
    "            'abs_error': 'neg_mean_absolute_error',\n",
    "            'squared_error': 'neg_mean_squared_error',\n",
    "            'r2':'r2'}\n",
    "\n",
    "    scores = cross_validate(best_mlp, X, Y, cv=10, scoring=scoring, return_train_score=True, return_estimator = True)\n",
    "    return scores\n",
    "\n",
    "mlp_model(data[[\"irradiance\"]][:100],\n",
    "np.asarray(data[[\"generated_energy\"]][:100]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
